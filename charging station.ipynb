{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ad19-d0a7-465f-aea2-6ac327f37074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prioritized Charging Requests:\n",
      "ID: Req-9, Priority: 0.6844\n",
      "ID: Req-6, Priority: 0.6434\n",
      "ID: Req-7, Priority: 0.5862\n",
      "ID: Req-14, Priority: 0.5020\n",
      "ID: Req-2, Priority: 0.4741\n",
      "ID: Req-3, Priority: 0.4701\n",
      "ID: Req-8, Priority: 0.4475\n",
      "ID: Req-11, Priority: 0.4462\n",
      "ID: Req-12, Priority: 0.4076\n",
      "ID: Req-15, Priority: 0.3781\n",
      "ID: Req-5, Priority: 0.3039\n",
      "ID: Req-1, Priority: 0.1928\n",
      "ID: Req-13, Priority: 0.1897\n",
      "ID: Req-10, Priority: 0.0985\n",
      "ID: Req-4, Priority: 0.0974\n",
      "Initial global model: 0.4967\n",
      "Round 1: Updated global model: 0.4968\n",
      "Round 2: Updated global model: 0.4969\n",
      "Round 3: Updated global model: 0.4967\n",
      "Round 4: Updated global model: 0.4966\n",
      "Round 5: Updated global model: 0.4964\n",
      "Round 6: Updated global model: 0.4963\n",
      "Round 7: Updated global model: 0.4963\n",
      "Round 8: Updated global model: 0.4962\n",
      "Round 9: Updated global model: 0.4960\n",
      "Round 10: Updated global model: 0.4960\n",
      "Final global model after 10 rounds: 0.4960\n",
      "\n",
      "VM Allocations:\n",
      "VM-1: Load = 5, Requests = ['Req-9', 'Req-14', 'Req-8', 'Req-15', 'Req-13']\n",
      "VM-2: Load = 5, Requests = ['Req-6', 'Req-2', 'Req-11', 'Req-5', 'Req-10']\n",
      "VM-3: Load = 5, Requests = ['Req-7', 'Req-3', 'Req-12', 'Req-1', 'Req-4']\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define parameters for federated learning\n",
    "NUM_FOG_NODES = 5  # Number of fog nodes\n",
    "NUM_GLOBAL_ROUNDS = 10  # Number of global federated learning rounds\n",
    "LEARNING_RATE = 0.01  # Learning rate\n",
    "DATASET_SIZE_PER_NODE = 1000  # Size of each fog node's dataset\n",
    "PRIORITY_WEIGHTS = {\"Q1\": 0.5, \"Q2\": 0.5}  # Weights for priority calculation\n",
    "\n",
    "# Simulate charging requests and their attributes\n",
    "def generate_charging_requests(num_requests):\n",
    "    \"\"\"Simulate charging requests with SoC and urgency values.\"\"\"\n",
    "    requests = []\n",
    "    for i in range(num_requests):\n",
    "        request = {\n",
    "            \"id\": f\"Req-{i+1}\",\n",
    "            \"SoC\": random.uniform(0, 1),  # State of charge (0 to 100%)\n",
    "            \"Urgency\": random.uniform(0, 1),  # Urgency level (0 to 1)\n",
    "        }\n",
    "        requests.append(request)\n",
    "    return requests\n",
    "\n",
    "# Calculate priorities\n",
    "def calculate_priorities(requests, weights):\n",
    "    \"\"\"Calculate priority scores for charging requests.\"\"\"\n",
    "    for req in requests:\n",
    "        req[\"Priority\"] = weights[\"Q1\"] * (1 - req[\"SoC\"]) + weights[\"Q2\"] * req[\"Urgency\"]\n",
    "    # Sort requests by priority (descending)\n",
    "    return sorted(requests, key=lambda x: x[\"Priority\"], reverse=True)\n",
    "\n",
    "# Simulate local model training\n",
    "def local_training(data_size, learning_rate):\n",
    "    \"\"\"Simulate one round of local training.\"\"\"\n",
    "   \n",
    "    model_update = np.random.randn() * learning_rate / np.sqrt(data_size)\n",
    "    return model_update\n",
    "# np.random.randn() : un facteur aléatoire dans la mise à jour du modèle ,\n",
    "#  learning_rate réduit l'impact de la valeur aléatoire pour éviter des mises à jour trop importantes.\n",
    "\n",
    "# Aggregate models at the cloud level\n",
    "def global_aggregation(local_updates, data_sizes):\n",
    "    \"\"\"Aggregate local models to form a global model.\"\"\"\n",
    "    total_data_size = sum(data_sizes)\n",
    "    global_model = sum((update * size / total_data_size for update, size in zip(local_updates, data_sizes)))\n",
    "    return global_model\n",
    "\n",
    "# Simulate the federated learning process\n",
    "def federated_learning(num_fog_nodes, num_rounds, learning_rate, dataset_size):\n",
    "    \"\"\"Perform federated learning.\"\"\"\n",
    "    # Initialize global model\n",
    "    global_model = np.random.randn()\n",
    "    print(f\"Initial global model: {global_model:.4f}\")\n",
    "    \n",
    "    # Simulate datasets for fog nodes\n",
    "    datasets = [dataset_size for _ in range(num_fog_nodes)]\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        local_updates = []\n",
    "        # Each fog node trains its model\n",
    "        #entraîne un modèle local avec les données et le taux d'apprentissage donnés.\n",
    "        #Il stocke la mise à jour du modèle dans une liste pour un usage ultérieur\n",
    "        for node_id in range(num_fog_nodes):\n",
    "            update = local_training(datasets[node_id], learning_rate)\n",
    "            local_updates.append(update)\n",
    "        \n",
    "        # Aggregate updates to update the global model\n",
    "        global_model += global_aggregation(local_updates, datasets)\n",
    "        print(f\"Round {round_num+1}: Updated global model: {global_model:.4f}\")\n",
    "    \n",
    "    return global_model\n",
    "\n",
    "# Simulate VM allocation\n",
    "def allocate_requests_to_vms(requests, num_vms, vm_capacity):\n",
    "    \"\"\"Distribute requests to VMs based on priority and load balancing.\"\"\"\n",
    "    vms = {f\"VM-{i+1}\": {\"Load\": 0, \"Capacity\": vm_capacity, \"Requests\": []} for i in range(num_vms)}\n",
    "    \n",
    "    for req in requests:\n",
    "        # Find VM with the minimum load that can accommodate the request\n",
    "        #Trouve les VM disponibles qui peuvent gérer chaque demande en vérifiant leur capacité et leur charge actuelle\n",
    "        suitable_vms = [(vm, info) for vm, info in vms.items() if info[\"Load\"] + 1 <= info[\"Capacity\"]]\n",
    "        if suitable_vms:\n",
    "            selected_vm = min(suitable_vms, key=lambda x: x[1][\"Load\"])[0]\n",
    "            vms[selected_vm][\"Load\"] += 1\n",
    "            vms[selected_vm][\"Requests\"].append(req[\"id\"])\n",
    "        else:\n",
    "            print(f\"Request {req['id']} could not be allocated due to capacity constraints.\")\n",
    "    \n",
    "    return vms\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate charging requests\n",
    "    num_requests = 15  # Number of charging requests\n",
    "    charging_requests = generate_charging_requests(num_requests)\n",
    "    \n",
    "    # Calculate priorities\n",
    "    prioritized_requests = calculate_priorities(charging_requests, PRIORITY_WEIGHTS)\n",
    "    print(\"Prioritized Charging Requests:\")\n",
    "    for req in prioritized_requests:\n",
    "        print(f\"ID: {req['id']}, Priority: {req['Priority']:.4f}\")\n",
    "    \n",
    "    # Perform federated learning\n",
    "    final_global_model = federated_learning(NUM_FOG_NODES, NUM_GLOBAL_ROUNDS, LEARNING_RATE, DATASET_SIZE_PER_NODE)\n",
    "    print(f\"Final global model after {NUM_GLOBAL_ROUNDS} rounds: {final_global_model:.4f}\")\n",
    "    \n",
    "    # Allocate requests to VMs\n",
    "    num_vms = 3  # Number of VMs\n",
    "    vm_capacity = 5  # Capacity of each VM\n",
    "    vm_allocations = allocate_requests_to_vms(prioritized_requests, num_vms, vm_capacity)\n",
    "    \n",
    "    print(\"\\nVM Allocations:\")\n",
    "    for vm, info in vm_allocations.items():\n",
    "        print(f\"{vm}: Load = {info['Load']}, Requests = {info['Requests']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d609e62-ccc1-44a3-ab0d-452e47179c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
